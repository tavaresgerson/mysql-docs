### 16.3.2 Lidar com uma Parada Inesperada de uma Replica

Para que a Replication seja resiliente a paradas inesperadas do servidor (às vezes descrita como *crash-safe*), deve ser possível para a Replica recuperar seu estado antes da parada. Esta seção descreve o impacto de uma parada inesperada de uma Replica durante a Replication e como configurar uma Replica para a melhor chance de recuperação para continuar a Replication.

Após uma parada inesperada de uma Replica, ao reiniciar, o Replication SQL Thread deve recuperar informações sobre quais *transactions* já foram executadas. As informações necessárias para a recuperação são armazenadas no *applier metadata repository* da Replica. Em versões mais antigas do MySQL Server, este repositório só podia ser criado como um arquivo no diretório de dados que era atualizado após a *transaction* ter sido aplicada. No MySQL 5.7, você pode usar em vez disso uma tabela [`InnoDB`](innodb-storage-engine.html "Chapter 14 The InnoDB Storage Engine") chamada `mysql.slave_relay_log_info` para armazenar o *applier metadata repository*. Como uma tabela, as atualizações no *applier metadata repository* são *committed* juntamente com as *transactions*, o que significa que a informação de progresso da Replica registrada nesse repositório é sempre consistente com o que foi aplicado ao Database, mesmo no caso de uma parada inesperada do servidor. Para configurar o MySQL 5.7 para armazenar o *applier metadata repository* como uma tabela [`InnoDB`](innodb-storage-engine.html "Chapter 14 The InnoDB Storage Engine"), defina a variável de sistema [`relay_log_info_repository`](replication-options-replica.html#sysvar_relay_log_info_repository) como `TABLE`. Para mais informações sobre o *applier metadata repository*, veja [Section 16.2.4, “Relay Log and Replication Metadata Repositories”](replica-logs.html "16.2.4 Relay Log and Replication Metadata Repositories").

O processo de recuperação pelo qual uma Replica se recupera de uma parada inesperada varia dependendo da configuração da Replica. Os detalhes do processo de recuperação são influenciados pelo método de Replication escolhido, se a Replica é *single-threaded* ou *multithreaded* e pela configuração das variáveis de sistema relevantes. O objetivo geral do processo de recuperação é identificar quais *transactions* já haviam sido aplicadas no Database da Replica antes da parada inesperada, e recuperar e aplicar as *transactions* que a Replica perdeu após a parada inesperada.

*   Para Replication baseada em GTID, o processo de recuperação precisa dos GTIDs das *transactions* que já foram recebidas ou *committed* pela Replica. As *transactions* ausentes podem ser recuperadas do Source usando *GTID auto-positioning*, que compara automaticamente as *transactions* do Source com as *transactions* da Replica e identifica as *transactions* ausentes.

*   Para Replication baseada em posição de arquivo, o processo de recuperação precisa de uma posição precisa do Replication SQL Thread (*applier*) mostrando a última *transaction* que foi aplicada na Replica. Com base nessa posição, o Replication I/O Thread (*receiver*) recupera do Binary Log do Source todas as *transactions* que devem ser aplicadas na Replica a partir desse ponto.

Usar Replication baseada em GTID torna mais fácil configurar a Replication para ser resiliente a paradas inesperadas. O *GTID auto-positioning* significa que a Replica pode identificar e recuperar de forma confiável as *transactions* ausentes, mesmo que haja *gaps* na sequência de *transactions* aplicadas.

A informação a seguir fornece combinações de configurações que são apropriadas para diferentes tipos de Replica para garantir a recuperação, na medida em que isso está sob o controle da Replication.

Importante

Alguns fatores fora do controle da Replication podem ter um impacto no processo de recuperação da Replication e no estado geral da Replication após o processo de recuperação. Em particular, as configurações que influenciam o processo de recuperação para *storage engines* individuais podem resultar na perda de *transactions* no caso de uma parada inesperada de uma Replica e, portanto, indisponíveis para o processo de recuperação da Replication. A configuração [`innodb_flush_log_at_trx_commit=1`](innodb-parameters.html#sysvar_innodb_flush_log_at_trx_commit) mencionada na lista abaixo é uma configuração chave para uma configuração de Replication que usa [`InnoDB`](innodb-storage-engine.html "Chapter 14 The InnoDB Storage Engine") com *transactions*. No entanto, outras configurações específicas do [`InnoDB`](innodb-storage-engine.html "Chapter 14 The InnoDB Storage Engine") ou de outros *storage engines*, especialmente aquelas relacionadas a *flushing* ou sincronização, também podem ter um impacto. Sempre verifique e aplique as recomendações feitas pelos *storage engines* escolhidos sobre configurações *crash-safe*.

A seguinte combinação de configurações em uma Replica é a mais resiliente a paradas inesperadas:

*   Quando a Replication baseada em GTID está em uso ([`gtid_mode=ON`](replication-options-gtids.html#sysvar_gtid_mode)), defina `MASTER_AUTO_POSITION=1`, o que ativa o *GTID auto-positioning* para a conexão com o Source, para identificar e recuperar automaticamente as *transactions* ausentes. Essa opção é definida usando uma instrução [`CHANGE MASTER TO`](change-master-to.html "13.4.2.1 CHANGE MASTER TO Statement"). Se a Replica tiver múltiplos canais de Replication, você precisará definir esta opção para cada canal individualmente. Para detalhes sobre como o *GTID auto-positioning* funciona, veja [Section 16.1.3.3, “GTID Auto-Positioning”](replication-gtids-auto-positioning.html "16.1.3.3 GTID Auto-Positioning"). Quando a Replication baseada em posição de arquivo está em uso, `MASTER_AUTO_POSITION=1` não é utilizado, e em vez disso a posição do Binary Log ou a posição do Relay Log é usada para controlar onde a Replication começa.

*   Defina [`sync_relay_log=1`](replication-options-replica.html#sysvar_sync_relay_log), que instrui o Replication I/O Thread a sincronizar o Relay Log para o disco após cada *transaction* recebida ser escrita nele. Isso significa que o registro da Replica da posição atual lida no Binary Log do Source (no *source metadata repository*) nunca está à frente do registro de *transactions* salvas no Relay Log. Observe que, embora esta configuração seja a mais segura, ela também é a mais lenta devido ao número de escritas em disco envolvidas. Com `sync_relay_log > 1`, ou `sync_relay_log=0` (onde a sincronização é tratada pelo sistema operacional), no caso de uma parada inesperada de uma Replica, pode haver *transactions committed* que não foram sincronizadas com o disco. Tais *transactions* podem fazer com que o processo de recuperação falhe se a Replica em recuperação, com base nas informações que ela tem no Relay Log conforme a última sincronização com o disco, tentar recuperar e aplicar as *transactions* novamente em vez de ignorá-las (*skipping*). Definir `sync_relay_log=1` é particularmente importante para uma Replica *multi-threaded*, onde o processo de recuperação falha se os *gaps* na sequência de *transactions* não puderem ser preenchidos usando as informações no Relay Log. Para uma Replica *single-threaded*, o processo de recuperação só precisa usar o Relay Log se a informação relevante não estiver disponível no *applier metadata repository*.

*   Defina [`innodb_flush_log_at_trx_commit=1`](innodb-parameters.html#sysvar_innodb_flush_log_at_trx_commit), que sincroniza os *logs* do [`InnoDB`](innodb-storage-engine.html "Chapter 14 The InnoDB Storage Engine") para o disco antes de cada *transaction* ser *committed*. Esta configuração, que é o padrão, garante que as tabelas [`InnoDB`](innodb-storage-engine.html "Chapter 14 The InnoDB Storage Engine") e os *logs* do [`InnoDB`](innodb-storage-engine.html "Chapter 14 The InnoDB Storage Engine") sejam salvos em disco, de modo que não haja mais a necessidade da informação no Relay Log referente à *transaction*. Combinada com a configuração [`sync_relay_log=1`](replication-options-replica.html#sysvar_sync_relay_log), esta configuração garante ainda mais que o conteúdo das tabelas [`InnoDB`](innodb-storage-engine.html "Chapter 14 The InnoDB Storage Engine") e dos *logs* do [`InnoDB`](innodb-storage-engine.html "Chapter 14 The InnoDB Storage Engine") seja consistente com o conteúdo do Relay Log em todos os momentos, para que a limpeza (*purging*) dos arquivos do Relay Log não possa causar *gaps* não preenchíveis na história de *transactions* da Replica no caso de uma parada inesperada.

*   Defina [`relay_log_info_repository = TABLE`](replication-options-replica.html#sysvar_relay_log_info_repository), que armazena a posição do Replication SQL Thread na tabela [`InnoDB`](innodb-storage-engine.html "Chapter 14 The InnoDB Storage Engine") `mysql.slave_relay_log_info` e a atualiza juntamente com o *commit* da *transaction* para garantir um registro que é sempre preciso. Esta configuração *não* é o padrão no MySQL 5.7. Se a configuração padrão `FILE` for usada, a informação é armazenada em um arquivo no diretório de dados que é atualizado após a *transaction* ter sido aplicada. Isso cria o risco de perder a sincronia com o Source, dependendo de em qual estágio de processamento de uma *transaction* a Replica parou, ou mesmo corrupção do próprio arquivo. Com a configuração [`relay_log_info_repository = FILE`](replication-options-replica.html#sysvar_relay_log_info_repository), a recuperação não é garantida.

*   Defina [`relay_log_recovery = ON`](replication-options-replica.html#sysvar_relay_log_recovery), que habilita a recuperação automática do Relay Log imediatamente após a inicialização do servidor (*server startup*). Esta variável global é padronizada como `OFF` e é somente leitura em tempo de execução (*runtime*), mas você pode defini-la como `ON` com a opção [`--relay-log-recovery`](replication-options-replica.html#sysvar_relay_log_recovery) na inicialização da Replica após uma parada inesperada. Observe que esta configuração ignora os arquivos de Relay Log existentes, caso estejam corrompidos ou inconsistentes. O processo de recuperação do Relay Log inicia um novo arquivo de Relay Log e busca *transactions* do Source começando na posição do Replication SQL Thread registrada no *applier metadata repository*. Os arquivos de Relay Log anteriores são removidos ao longo do tempo pelo mecanismo normal de limpeza da Replica.

Para uma Replica *multithreaded*, a partir do MySQL 5.7.13, definir [`relay_log_recovery = ON`](replication-options-replica.html#sysvar_relay_log_recovery) lida automaticamente com quaisquer inconsistências e *gaps* na sequência de *transactions* que foram executadas a partir do Relay Log. Esses *gaps* podem ocorrer quando a Replication baseada em posição de arquivo está em uso. (Para mais detalhes, veja [Section 16.4.1.32, “Replication and Transaction Inconsistencies”](replication-features-transaction-inconsistencies.html "16.4.1.32 Replication and Transaction Inconsistencies").) O processo de recuperação do Relay Log lida com os *gaps* usando o mesmo método que a instrução [`START SLAVE UNTIL SQL_AFTER_MTS_GAPS`](start-slave.html "13.4.2.5 START SLAVE Statement") usaria. Quando a Replica atinge um estado consistente e sem *gaps* (*gap-free*), o processo de recuperação do Relay Log continua a buscar mais *transactions* do Source, começando na posição do Replication SQL Thread. Em versões do MySQL anteriores ao MySQL 5.7.13, este processo não era automático e exigia iniciar o servidor com [`relay_log_recovery = OFF`](replication-options-replica.html#sysvar_relay_log_recovery), iniciar a Replica com [`START SLAVE UNTIL SQL_AFTER_MTS_GAPS`](start-slave.html "13.4.2.5 START SLAVE Statement") para corrigir quaisquer inconsistências de *transaction*, e então reiniciar a Replica com [`relay_log_recovery = ON`](replication-options-replica.html#sysvar_relay_log_recovery). Quando a Replication baseada em GTID está em uso, a partir do MySQL 5.7.28 uma Replica *multithreaded* verifica primeiro se `MASTER_AUTO_POSITION` está definido como `ON` e, se estiver, omite a etapa de cálculo das *transactions* que devem ser ignoradas ou não ignoradas, de modo que os Relay Logs antigos não são necessários para o processo de recuperação.